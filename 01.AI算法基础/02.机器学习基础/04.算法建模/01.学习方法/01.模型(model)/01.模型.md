# 1. 模型
## 1.1. 概率模型与非概率模型
&emsp;&emsp;监督学习的模型分为概率模型和非概率模型，由条件概率分布 $P(Y|X)$ 或决策函数 $Y=f(X)$ 表示，当进行预测时分别写作 $P(y|x)$ 或 $y=f(x)$。

&emsp;&emsp;监督学习的任务就是从数据中学习一个模型，这个模型的一般形式为决策函数或者条件概率分布。

## 1.2. 生成方法和判别方法
&emsp;&emsp;监督学习方法又分生成方法（Generative approach）和判别方法（Discriminative approach），所学到的模型分别称为生成模型（Generative Model）和判别模型（Discriminative Model）。

### 1.2.1. 判别方法与判别模型
&emsp;&emsp;由数据直接学习决策函数 $Y=f(X)$ 或者条件概率分布 $P(Y|X)$ 作为预测的模型，即判别模型。基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。

&emsp;&emsp;典型的判别模型包括:
- k近邻
- 逻辑回归
- 线性回归
- 支持向量机
- 提升方法
- 条件随机场
- 人工神经网络
- 随机森林
- 决策树
- 感知器

### 1.2.2. 生成方法与生成模型
&emsp;&emsp;由数据学习联合概率密度分布 $P(X,Y)$，然后求出条件概率分布 $P(Y|X)$ 作为预测的模型，即生成模型： $P(Y|X)= P(X,Y)/ P(X)$ 。基本思想是首先建立样本的联合概率概率密度模型 $P(X,Y)$ ，然后再得到后验概率 $P(Y|X)$。

&emsp;&emsp;这里先求出 $P(X,Y)$ 才得到 $P(Y|X)$ 的，然后这个过程还得先求出 $P(X)$ 。 $P(X)$ 就是训练数据的概率分布。需要数据样本非常多的时候，得到的P(X)才能很好的描述数据真正的分布。

&emsp;&emsp;这样的方法之所以称为生成方法，是因为模型表示了给定输入 $X$ 产生输出 $Y$ 的生成关系。用于随机生成的观察值建模，特别是在给定某些隐藏参数情况下。

&emsp;&emsp;典型的生成模型有：
- 朴素贝叶斯
- 隐马尔科夫模型

### 1.2.3. 生成模型与判别模型的差异
&emsp;&emsp;生成模型是所有变量的全概率模型，而判别模型是在给定观测变量值前提下目标变量条件概率模型。因此生成模型能够用于模拟（即生成）模型中任意变量的分布情况，而判别模型只能根据观测变量得到目标变量的采样。判别模型不对观测变量的分布建模，因此它不能够表达观测变量与目标变量之间更复杂的关系。因此，生成模型更适用于无监督的任务。

&emsp;&emsp;与生成模型不同，判别模型不考虑 ${\displaystyle x}$ 与 ${\displaystyle y}$ 间的联合分布。对于诸如分类和回归问题，由于不考虑联合概率分布，采用判别模型可以取得更好的效果。而生成模型在刻画复杂学习任务中的依赖关系方面则较判别模型更加灵活。大部分判别模型本身是监督学习模型，不易扩展用于无监督学习过程。
