# 简介
&emsp;&emsp;概率论（英语：Probability theory）是集中研究概率及随机现象的数学分支，是研究随机性或不确定性等现象的数学。

&emsp;&emsp;概率论主要研究对象为**随机事件**、**随机变量**以及**随机过程**。对于随机事件是不可能准确预测其结果的，然而对于一系列的独立随机事件——例如掷骰子、扔硬币、抽扑克牌以及轮盘等，会呈现出一定的、可以被用于研究及预测的规律，两个用来描述这些规律的最具代表性的数学结论分别是大数定律和中心极限定理。

&emsp;&emsp;概率论中的两个重要概念为随机变量和随机变量的概率分布两种。

# 概率的定义
## 传统概率 (古典概率)( 拉普拉斯概率 )
&emsp;&emsp;传统概率的定义是由法国数学家拉普拉斯 ( Laplace ) 提出的。如果一个随机试验所包含的单位事件是有限的，且每个单位事件发生的可能性均相等，则这个随机试验叫做拉普拉斯试验。在拉普拉斯试验中，事件 ${\displaystyle A}$ 在事件空间 ${\displaystyle S}$ 中的概率 ${\displaystyle P(A)}$ 为：

$$ P(A)={\displaystyle \frac {构成事件A的元素数目} {构成事件空间S的所有元素数目}}$$

&emsp;&emsp;例如，在一次同时掷一个硬币和一个骰子的随机试验中，假设事件 ${\displaystyle A}$ 为获得国徽面且点数大于 4 ，那么事件 ${\displaystyle A}$ 的概率应该有如下计算方法：
${\displaystyle S=} { ( 国徽，1 点 )，( 数字，1 点 )，( 国徽，2 点 )，( 数字，2 点 )，( 国徽，3 点 )，( 数字，3 点 )，( 国徽，4 点 )，( 数字，4 点 )，( 国徽，5 点 )，( 数字，5 点 )，( 国徽，6 点 )，( 数字，6 点 ) }$\
 ${\displaystyle A} ＝{( 国徽，5 点 )，( 国徽，6 点 )}$\
 按照拉普拉斯定义， ${\displaystyle A}$ 的概率为:
$${\displaystyle P(A)={\frac {2}{12}}={\frac {1}{6}}}$$

&emsp;&emsp;注意到在拉普拉斯试验中存在着若干的疑问，在现实中是否存在着其单位事件的概率具有精确相同的概率值的试验? 因为我们不知道，硬币以及骰子是否完美，即骰子制造的是否均匀，其重心是否位于正中心，以及轮盘是否倾向于某一个数字。 尽管如此，传统概率在实践中被广泛应用于确定事件的概率值，其理论根据是： 如果没有足够的论据来证明一个事件的概率大于另一个事件的概率，那么可以认为这两个事件的概率值相等。

&emsp;&emsp;如果仔细观察这个定义会发现拉普拉斯用概率解释了概率，定义中用了相同的可能性 ( 原文是 également possible )一词，其实指的就是"相同的概率"。这个定义也并没有说出，到底什么是概率，以及如何用数字来确定概率。在现实生活中也有一系列问题，无论如何不能用传统概率定义来解释，比如，人寿保险公司无法确定一个 50 岁的人在下一年将死去的概率。

## 统计概率
&emsp;&emsp;继传统概率论之后，英国逻辑学家约翰·维恩和奥地利数学家理查德提出建立在频率理论基础上的统计概率。他们认为，获得一个事件的概率值的唯一方法是通过对该事件进行 100 次，1000 次或者甚至 10000 次的前后相互独立的 ${\displaystyle n}$ 次随机试验，针对每次试验均记录下绝对频率值 ${\displaystyle h_{n}} (A)$ 和相对频率值 ${\displaystyle f_{n}} (A)$，随着试验次数 ${\displaystyle n}$ 的增加，会出现如下事实，即相对频率值会趋于稳定，它在一个特定的值上下浮动，也即是说存在着一个极限值 ${\displaystyle P(A)}$ ，相对频率值趋向于这个极限值。这个极限值被称为统计概率，表示为：

$${\displaystyle P(A)=\lim_{n \to \infty} f_{n}(A)}$$


&emsp;&emsp;例如，若想知道在一次掷骰子的随机试验中获得 6 点的概率值可以对其进行 3000 次前后独立的扔掷试验，在每一次试验后记录下出现 6 点的次数，然后通过计算相对频率值可以得到趋向于某一个数的统计概率值。

扔掷数 | 获得6点的绝对频率 | 获得6点的相对频率
:-: | :-:| :-:
1 |	1 |	1.00000
2 |	1 |	0.50000
3 |	1 |	0.33333
4 |	1 |	0.25000
5 |	2 |	0.40000
10 |	2 |	0.20000
20 |	5 |	0.25000
100 |	12 |	0.12000
200 |	39 |	0.19500
300 |	46 |	0.15333
400 |	72 |	0.18000
500 |	76 |	0.15200
600 |	102 |	0.17000
700 |	120 |	0.17143
1000 |	170 |	0.17000
2000 |	343 |	0.17150
3000 |	506 |	0.16867

# 概率的类型

## 条件概率
&emsp;&emsp;条件概率（英语：conditional probability）是事件A在事件B发生的条件下发生的概率。

&emsp;&emsp;A和B的条件概率表示为 $P(A|B)$ ，读作“事件A在事件B发生的条件下发生的概率”。

## 联合概率
&emsp;&emsp;联合概率表示两个事件A和B共同发生的概率。

&emsp;&emsp;A与B的联合概率表示为 ${\displaystyle P(A\cap B)}$ 或者 ${\displaystyle P(A,B)}$ 或者 ${\displaystyle P(AB)}$ 。

## 边缘概率
&emsp;&emsp;边缘概率是某个事件发生的概率。

&emsp;&emsp;在联合概率中，把最终结果中不需要的那些事件合并成其事件的全概率而消失（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率），这称为边缘化（marginalization）。

&emsp;&emsp;A的边缘概率表示为 $P(A)$ ，B的边缘概率表示为 $P(B)$ 。
