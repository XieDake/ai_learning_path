# 反向传播
&emsp;&emsp;反向传播（英语：Back Propagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。

&emsp;&emsp;任何监督式学习算法的目标是找到一个能把一组输入最好地映射到其正确的输出的函数。反向传播算法的发展的目标和动机是找到一种训练的多层神经网络的方法，于是它可以学习合适的内部表达来让它学习任意的输入到输出的映射。

## 反向传播算法描述
&emsp;&emsp;反向传播算法（BP 算法）通过链式法则对每层进行迭代，对每个输入值想得到的已知输出，来计算损失函数梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。

&emsp;&emsp;它主要由两个阶段组成：**激励传播**与**权重更新**。

**第1阶段：激励传播**

每次迭代中的传播环节包含两步：
- （前向传播阶段）将训练输入送入网络以获得**激励响应**；
- （反向传播阶段）将激励响应同训练输入对应的目标输出求差，从而获得输出层和隐藏层的**响应误差**。

**第2阶段：权重更新**

对于每个突触上的权重，按照以下步骤进行更新：
- 将**输入激励**和**响应误差**相乘，从而获得**权重的梯度**；
- 将这个梯度乘上一个比例（学习率）并取反后加到权重上，并更新该**权重**。

梯度的方向指明了误差扩大的方向，因此在更新权重的时候需要对其取反，从而减小权重引起的误差。

&emsp;&emsp;第 1 和第 2 阶段可以反复循环迭代，直到网络对输入的响应达到满意的预定的目标范围为止。
